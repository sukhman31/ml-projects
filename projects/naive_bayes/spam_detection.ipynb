{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails, labels = [],[]\n",
    "\n",
    "path_spam = './enron1/spam'\n",
    "\n",
    "for filename in glob.glob(os.path.join(path_spam,'*.txt')):\n",
    "    with open(filename,'r',encoding='ISO-8859-1') as f:\n",
    "        text = f.read()\n",
    "        emails.append(text)\n",
    "        labels.append(1)\n",
    "\n",
    "path_ham = './enron1/ham'\n",
    "\n",
    "for filename in glob.glob(os.path.join(path_ham,'*.txt')):\n",
    "    with open(filename,'r',encoding='ISO-8859-1') as f:\n",
    "        text = f.read()\n",
    "        emails.append(text)\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5172\n"
     ]
    }
   ],
   "source": [
    "print(len(emails))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data: \n",
    "* Remove names\n",
    "* Remove stopwords\n",
    "* Remove numbers and punctuation\n",
    "* Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def letters_only(s):\n",
    "    return s.isalpha()\n",
    "all_names = set(names.words())\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_docs(docs):\n",
    "    cleaned_docs = []\n",
    "    for doc in docs:\n",
    "        cleaned_docs.append(' '.join([lemmatizer.lemmatize(word.lower()) for word in doc.split() if letters_only(word) and word not in all_names]))\n",
    "    return cleaned_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_mail = clean_docs(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dobmeos with hgh my energy level ha gone up stukm introducing doctor formulated hgh human growth hormone also called hgh is referred to in medical science a the master hormone it is very plentiful when we are young but near the age of twenty one our body begin to produce le of it by the time we are forty nearly everyone is deficient in hgh and at eighty our production ha normally diminished at least advantage of hgh increased muscle strength loss in body fat increased bone density lower blood pressure quickens wound healing reduces cellulite improved vision wrinkle disappearance increased skin thickness texture increased energy level improved sleep and emotional stability improved memory and mental alertness increased sexual potency resistance to common illness strengthened heart muscle controlled cholesterol controlled mood swing new hair growth and color restore read more at this website unsubscribe'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_mail[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating term frequencies for the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words='english', max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_docs = cv.fit_transform(clean_mail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dobmeos with hgh my energy level ha gone up stukm introducing doctor formulated hgh human growth hormone also called hgh is referred to in medical science a the master hormone it is very plentiful when we are young but near the age of twenty one our body begin to produce le of it by the time we are forty nearly everyone is deficient in hgh and at eighty our production ha normally diminished at least advantage of hgh increased muscle strength loss in body fat increased bone density lower blood pressure quickens wound healing reduces cellulite improved vision wrinkle disappearance increased skin thickness texture increased energy level improved sleep and emotional stability improved memory and mental alertness increased sexual potency resistance to common illness strengthened heart muscle controlled cholesterol controlled mood swing new hair growth and color restore read more at this website unsubscribe'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_mail[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 265)\t2\n",
      "  (0, 482)\t2\n",
      "  (0, 363)\t2\n",
      "  (0, 229)\t1\n",
      "  (0, 361)\t2\n",
      "  (0, 103)\t1\n",
      "  (0, 997)\t1\n",
      "  (0, 86)\t2\n",
      "  (0, 72)\t1\n",
      "  (0, 476)\t1\n",
      "  (0, 898)\t1\n",
      "  (0, 690)\t1\n",
      "  (0, 506)\t1\n",
      "  (0, 865)\t1\n",
      "  (0, 585)\t1\n",
      "  (0, 151)\t1\n",
      "  (0, 714)\t1\n",
      "  (0, 969)\t1\n",
      "  (0, 933)\t1\n"
     ]
    }
   ],
   "source": [
    "print(term_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ability', 'able', 'access', 'according', 'account'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names_out()\n",
    "feature_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(B|A) = P(A|B)*P(B)/P(A)\n",
    "\n",
    "* P(B) is called the Prior\n",
    "* P(B|A) is called the posterior\n",
    "* P(A|B) is called the likelihood\n",
    "* P(A) is called the evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.7099767981438515, 1: 0.2900232018561485}\n"
     ]
    }
   ],
   "source": [
    "#Calculating the Prior\n",
    "\n",
    "def get_prior(labels):\n",
    "    '''prior basically implies the probability of a mail in \n",
    "    training set belonging to ham or spam. This is basic probability'''\n",
    "    len_ham,len_spam = 0,0\n",
    "    for l in labels:\n",
    "        if l==0:\n",
    "            len_ham += 1\n",
    "        else:\n",
    "            len_spam += 1\n",
    "    prior = {0: float(len_ham/len(labels)), 1: float(len_spam/len(labels))}\n",
    "    return prior\n",
    "\n",
    "prior = get_prior(labels)\n",
    "print(prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the Likelihood\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def label_index(labels):\n",
    "    label_index = {0:[],1:[]}\n",
    "    for index,l in enumerate(labels):\n",
    "        if l==0:\n",
    "            label_index[0].append(index)\n",
    "        else:\n",
    "            label_index[1].append(index)\n",
    "    return label_index\n",
    "\n",
    "def get_likelihood(label_index,term_docs, laplace_smoothing=0):\n",
    "    '''likelihood basically states if mail is spam/ham then what is the probabilty that\n",
    "    this category will contain a particular word\n",
    "    '''\n",
    "    likelihood = {}\n",
    "    for label,index in label_index.items():\n",
    "        likelihood[label] = term_docs[index,:].sum(axis=0) + laplace_smoothing\n",
    "        likelihood[label] = np.asarray(likelihood[label])[0]\n",
    "        total_sum = likelihood[label].sum()\n",
    "        likelihood[label] = likelihood[label]/float(total_sum)\n",
    "    return likelihood\n",
    "\n",
    "label_index = label_index(labels)\n",
    "laplace_smoothing = 1\n",
    "likelihood = get_likelihood(label_index,term_docs,laplace_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now the final step is to calculate the posterior\n",
    "\n",
    "def get_posterior(term_docs,prior,likelihood):\n",
    "    '''we will calculate summation of natural logs of the conditional probabilities\n",
    "    instead of multiplying them which may cause overflow and then convert the final value'''\n",
    "    num_docs = term_docs.shape[0]\n",
    "    posteriors = []\n",
    "    for i in range(num_docs):\n",
    "        posterior = {key: np.log(prior_label) for key,prior_label in prior.items()}\n",
    "        for label, likelihood_label in likelihood.items():\n",
    "            term_document_vector = term_docs.getrow(i)\n",
    "            counts = term_document_vector.data\n",
    "            indices = term_document_vector.indices\n",
    "            for count,index in zip(counts,indices):\n",
    "                posterior[label] += np.log(likelihood_label[index])*count\n",
    "            min_log_posterior = min(posterior.values())\n",
    "            for label in posterior:\n",
    "                try:\n",
    "                    posterior[label] = np.exp(posterior[label]-min_log_posterior)\n",
    "                except:\n",
    "                    posterior[label] = float('inf')\n",
    "            sum_posterior = sum(posterior.values())\n",
    "            for label in posterior:\n",
    "                if posterior[label]==float('inf'):\n",
    "                    posterior[label] = 1.0\n",
    "                else:\n",
    "                    posterior[label] /= sum_posterior\n",
    "        posteriors.append(posterior.copy())\n",
    "    return posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"\"\"Hi Sukhman,\n",
    "\n",
    "This is going to be a bit of a different email than normal since I want to talk all about New Years and the idea of New Year's resolutions. To be honest almost everyone does New Year's resolutions wrong (including you) which is why most people fail at sticking to their resolutions and meaningfully changing their lives. In this article I want to talk about why most people will fail their New Year's resolutions, and what you can do to actually succeed \"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0: 1.0, 1: 4.212294095348821e-46}]\n"
     ]
    }
   ],
   "source": [
    "cleaned_test = clean_docs(test)\n",
    "terms_test = cv.transform(cleaned_test)\n",
    "posterior = get_posterior(terms_test,prior,likelihood)\n",
    "print(posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
