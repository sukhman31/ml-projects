{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails, labels = [],[]\n",
    "\n",
    "path_spam = './enron1/spam'\n",
    "\n",
    "for filename in glob.glob(os.path.join(path_spam,'*.txt')):\n",
    "    with open(filename,'r',encoding='ISO-8859-1') as f:\n",
    "        text = f.read()\n",
    "        emails.append(text)\n",
    "        labels.append(1)\n",
    "\n",
    "path_ham = './enron1/ham'\n",
    "\n",
    "for filename in glob.glob(os.path.join(path_ham,'*.txt')):\n",
    "    with open(filename,'r',encoding='ISO-8859-1') as f:\n",
    "        text = f.read()\n",
    "        emails.append(text)\n",
    "        labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5172\n"
     ]
    }
   ],
   "source": [
    "print(len(emails))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the data: \n",
    "* Remove names\n",
    "* Remove stopwords\n",
    "* Remove numbers and punctuation\n",
    "* Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def letters_only(s):\n",
    "    return s.isalpha()\n",
    "all_names = set(names.words())\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_docs(docs):\n",
    "    cleaned_docs = []\n",
    "    for doc in docs:\n",
    "        cleaned_docs.append(' '.join([lemmatizer.lemmatize(word.lower()) for word in doc.split() if letters_only(word) and word not in all_names]))\n",
    "    return cleaned_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_mail = clean_docs(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dobmeos with hgh my energy level ha gone up stukm introducing doctor formulated hgh human growth hormone also called hgh is referred to in medical science a the master hormone it is very plentiful when we are young but near the age of twenty one our body begin to produce le of it by the time we are forty nearly everyone is deficient in hgh and at eighty our production ha normally diminished at least advantage of hgh increased muscle strength loss in body fat increased bone density lower blood pressure quickens wound healing reduces cellulite improved vision wrinkle disappearance increased skin thickness texture increased energy level improved sleep and emotional stability improved memory and mental alertness increased sexual potency resistance to common illness strengthened heart muscle controlled cholesterol controlled mood swing new hair growth and color restore read more at this website unsubscribe'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_mail[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating term frequencies for the cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(stop_words='english', max_features=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_docs = cv.fit_transform(clean_mail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dobmeos with hgh my energy level ha gone up stukm introducing doctor formulated hgh human growth hormone also called hgh is referred to in medical science a the master hormone it is very plentiful when we are young but near the age of twenty one our body begin to produce le of it by the time we are forty nearly everyone is deficient in hgh and at eighty our production ha normally diminished at least advantage of hgh increased muscle strength loss in body fat increased bone density lower blood pressure quickens wound healing reduces cellulite improved vision wrinkle disappearance increased skin thickness texture increased energy level improved sleep and emotional stability improved memory and mental alertness increased sexual potency resistance to common illness strengthened heart muscle controlled cholesterol controlled mood swing new hair growth and color restore read more at this website unsubscribe'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_mail[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 560)\t2\n",
      "  (0, 1019)\t2\n",
      "  (0, 767)\t2\n",
      "  (0, 739)\t1\n",
      "  (0, 491)\t1\n",
      "  (0, 759)\t2\n",
      "  (0, 226)\t1\n",
      "  (0, 1122)\t1\n",
      "  (0, 1104)\t1\n",
      "  (0, 1993)\t1\n",
      "  (0, 1195)\t1\n",
      "  (0, 45)\t1\n",
      "  (0, 184)\t2\n",
      "  (0, 158)\t1\n",
      "  (0, 1003)\t1\n",
      "  (0, 1816)\t1\n",
      "  (0, 1416)\t1\n",
      "  (0, 1219)\t1\n",
      "  (0, 34)\t1\n",
      "  (0, 877)\t5\n",
      "  (0, 1186)\t2\n",
      "  (0, 1061)\t1\n",
      "  (0, 638)\t1\n",
      "  (0, 1069)\t1\n",
      "  (0, 1393)\t1\n",
      "  (0, 1637)\t1\n",
      "  (0, 331)\t1\n",
      "  (0, 788)\t1\n",
      "  (0, 1765)\t1\n",
      "  (0, 1203)\t1\n",
      "  (0, 319)\t1\n",
      "  (0, 1459)\t1\n",
      "  (0, 1944)\t1\n",
      "  (0, 1881)\t1\n"
     ]
    }
   ],
   "source": [
    "print(term_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ability', 'able', 'accept', 'acceptance', 'access'], dtype=object)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names_out()\n",
    "feature_names[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(B|A) = P(A|B)*P(B)/P(A)\n",
    "\n",
    "* P(B) is called the Prior\n",
    "* P(B|A) is called the posterior\n",
    "* P(A|B) is called the likelihood\n",
    "* P(A) is called the evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.7099767981438515, 1: 0.2900232018561485}\n"
     ]
    }
   ],
   "source": [
    "#Calculating the Prior\n",
    "\n",
    "def get_prior(labels):\n",
    "    '''prior basically implies the probability of a mail in \n",
    "    training set belonging to ham or spam. This is basic probability'''\n",
    "    len_ham,len_spam = 0,0\n",
    "    for l in labels:\n",
    "        if l==0:\n",
    "            len_ham += 1\n",
    "        else:\n",
    "            len_spam += 1\n",
    "    prior = {0: float(len_ham/len(labels)), 1: float(len_spam/len(labels))}\n",
    "    return prior\n",
    "\n",
    "prior = get_prior(labels)\n",
    "print(prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the Likelihood\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_label_index(labels):\n",
    "    label_index = {0:[],1:[]}\n",
    "    for index,l in enumerate(labels):\n",
    "        if l==0:\n",
    "            label_index[0].append(index)\n",
    "        else:\n",
    "            label_index[1].append(index)\n",
    "    return label_index\n",
    "\n",
    "def get_likelihood(label_index,term_docs, laplace_smoothing=0):\n",
    "    '''likelihood basically states if mail is spam/ham then what is the probabilty that\n",
    "    this category will contain a particular word\n",
    "    '''\n",
    "    likelihood = {}\n",
    "    for label,index in label_index.items():\n",
    "        likelihood[label] = term_docs[index,:].sum(axis=0) + laplace_smoothing\n",
    "        likelihood[label] = np.asarray(likelihood[label])[0]\n",
    "        total_sum = likelihood[label].sum()\n",
    "        likelihood[label] = likelihood[label]/float(total_sum)\n",
    "    return likelihood\n",
    "\n",
    "label_index = get_label_index(labels)\n",
    "laplace_smoothing = 1\n",
    "likelihood = get_likelihood(label_index,term_docs,laplace_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now the final step is to calculate the posterior\n",
    "\n",
    "def get_posterior(term_docs,prior,likelihood):\n",
    "    '''we will calculate summation of natural logs of the conditional probabilities\n",
    "    instead of multiplying them which may cause overflow and then convert the final value'''\n",
    "    num_docs = term_docs.shape[0]\n",
    "    posteriors = []\n",
    "    for i in range(num_docs):\n",
    "        posterior = {key: np.log(prior_label) for key,prior_label in prior.items()}\n",
    "        for label, likelihood_label in likelihood.items():\n",
    "            term_document_vector = term_docs.getrow(i)\n",
    "            counts = term_document_vector.data\n",
    "            indices = term_document_vector.indices\n",
    "            for count,index in zip(counts,indices):\n",
    "                posterior[label] += np.log(likelihood_label[index])*count\n",
    "        min_log_posterior = min(posterior.values())\n",
    "        for label in posterior:\n",
    "            try:\n",
    "                posterior[label] = np.exp(posterior[label]-min_log_posterior)\n",
    "            except:\n",
    "                posterior[label] = float('inf')\n",
    "        sum_posterior = sum(posterior.values())\n",
    "        for label in posterior:\n",
    "            if posterior[label]==float('inf'):\n",
    "                posterior[label] = 1.0\n",
    "            else:\n",
    "                posterior[label] /= sum_posterior\n",
    "        posteriors.append(posterior.copy())\n",
    "    return posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing our new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"\"\"Having problems in bed? We can help! cialis allows men to enjoy a fully normal\n",
    "        sex lige without having to plant the sexual act.if we let things terrify us, life will not be worth living\n",
    "        brevity is the soul of lingerie .\n",
    "        suspicion always haunts the guilty mind .\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{0: 1.336945845936172e-10, 1: 0.9999999998663054}]\n"
     ]
    }
   ],
   "source": [
    "cleaned_test = clean_docs(test)\n",
    "terms_test = cv.transform(cleaned_test)\n",
    "posterior = get_posterior(terms_test,prior,likelihood)\n",
    "print(posterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy metrics for the model\n",
    "* Split the data into test-train sets and evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(clean_mail,labels,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_docs_train = cv.fit_transform(x_train)\n",
    "label_index_train = get_label_index(y_train)\n",
    "prior = get_prior(label_index)\n",
    "likelihood = get_likelihood(label_index_train,term_docs_train, laplace_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SUKHMAN\\AppData\\Local\\Temp\\ipykernel_24584\\3418514014.py:19: RuntimeWarning: overflow encountered in exp\n",
      "  posterior[label] = np.exp(posterior[label]-min_log_posterior)\n"
     ]
    }
   ],
   "source": [
    "term_docs_test = cv.transform(x_test)\n",
    "posterior = get_posterior(term_docs_test, prior, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on 1707 testing samples is:95.3%\n"
     ]
    }
   ],
   "source": [
    "correct = 0.0\n",
    "for pred, actual in zip(posterior, y_test):\n",
    "    if actual == 1:\n",
    "        if pred[1] >= 0.5:\n",
    "            correct += 1\n",
    "    elif pred[0] > 0.5:\n",
    "        correct += 1\n",
    "print('The accuracy on {0} testing samples is:{1:.1f}%'.format(len(y_test), correct/len(y_test)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
